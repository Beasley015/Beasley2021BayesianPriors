---
title: 'Appendix S2: Example of informed priors using simulated data.'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```


### Simulate the community

```{r, include = F}
library(R2jags)
library(boot)
library(abind)
library(ggplot2)
```

```{r}
# Set seed
set.seed(23)

# Global variables
nspec <- 10
nsite <- 20
nsurvey <- 4

Ks <- rep(nsurvey, nsite) # vector of surveys at each site

# Vector of covariate responses: half of species respond negatively
resp2cov <- c(rnorm(n = 5, sd = 0.25),
              rnorm(n = 5, mean = -3, sd = 0.25))

resp2cov <- sample(resp2cov)

# Covariate values for sites
cov <- sort(rnorm(n = nsite))
```

```{r}
# Get probs from a beta distribution
sim.occ <- rbeta(n = nspec, shape1 = 2, shape2 = 3)

# Write function to simulate true occupancy state
tru.mats <- function(spec=nspec, site=nsite,
                     alpha1=resp2cov){
  #Get site-level psi to account for covariates
  alpha0 <- logit(sim.occ)
  
  #Create empty matrix to store occupancy probs
  logit.psi <- matrix(NA, nrow = spec, ncol = site)
  
  # Generate occupancy probs
  for(i in 1:spec){
    logit.psi[i,] <- alpha0[i] + alpha1[i]*cov
  }
  
  # Transform
  psi <- plogis(logit.psi)
  
  # Generate true occupancy state
  nlist<-list()
  for(a in 1:spec){
    nlist[[a]] <- rbinom(n = site, size = 1, prob = psi[a,])
  }
  
  #Turn abundance vectors into abundance matrix
  ns<-do.call(rbind, nlist)
  
  return(ns)
}

# Get true occupancy states
tru <- tru.mats()
print(tru[,1:10])
```

```{r}
# Generate mean detection probabilities from beta dist
mean.p <- rbeta(n = nspec, shape1 = 2, shape2 = 8)
mean.p <- sort(mean.p, decreasing = T)

# Generate detection histories
get.obs <- function(mat, specs){
  #Detection intercept and cov responses
  beta0<-logit(mean.p) #put it on logit scale

  #Logit link function
  logit.p <- array(NA, dim = c(nsite, nsurvey, specs))
  for(i in 1:specs){
    for(j in 1:nsite){
      for(k in 1:nsurvey){
        logit.p[j,,i] <- beta0[i]
      }
    }
  }

  p <- plogis(logit.p)

  #Simulate observation data
  L<-list()

  for(b in 1:specs){
    y<-matrix(NA, ncol = nsite, nrow = nsurvey)
    for(a in 1:nsurvey){
      y[a,]<-rbinom(n = nsite, size = 1, prob = p[,,b]*mat[b,])
    }
    L[[b]]<-t(y)
  }

  #Smash it into array
  obs<-array(as.numeric(unlist(L)), 
                 dim=c(nsite, nsurvey, specs))

  return(obs)
}

obs.data <- get.obs(mat = tru, specs = nspec)

# Look at observed occurrence
maxobs <- apply(obs.data, c(1,3), max)
colSums(maxobs) # One species was not observed
```

### Remove undetected species from observed dataset and reorder data

```{r}
# Remove undetected species
obs.data <- obs.data[,,-which(colSums(maxobs) == 0)]

# Function to reorder true values
reorder <- function(x){
  if (length(dim(x)) == 0){
    nondets <- which(colSums(maxobs) == 0)
    copy <- x[nondets]
    x <- x[-nondets]
    new <- c(x, copy)
    return(new)
    }
  else {
    nondets <- which(colSums(maxobs) == 0)
    copy <- x[nondets,]
    x <- x[-nondets,]
    new <- rbind(x, copy)
    return(new)
    }
}

# Reorder simulated values
sim.occ <- reorder(sim.occ)
mean.p <- reorder(mean.p)
resp2cov <- reorder(resp2cov)
tru <- reorder(tru)
maxobs <- reorder(maxobs)

# Augment observed with all-zero encounter history
ems.array <- array(0, dim = c(nsite, nsurvey, 1))
obs.aug <- abind(obs.data, ems.array, along = 3)
```

### Define the informed prior

```{r}
# Get true covariate value
resp2cov[10]

# Write script for priors in JAGS language
priors <- "#Info for species-level prior distribution
            inf.mean <- -3 #mean of distribution
            inf.var <- 0.5 #variance of distribution
            
          #Define prior weights: how much each distribution 
          #contributes to the final aggregate
          #Hyperprior first, then informed
            weights <- c(0.5, 0.5) #these are equal weights
          
          #Pool the distributions  
            lb[1] <- weights[1]/(1/tau.a0) 
            #1/tau.a0 is the variation of hyperprior
            lb[2] <- weights[2]/inf.var
            
            pooled.var <- 1/sum(lb)
            pooled.mean <- sum(lb*c(a0.mean,inf.mean))
              *pooled.var
          
            for(i in 1:(spec+aug)){
              #Create priors from hyperpriors/aggregated prior
              w[i] ~ dbern(omega) 
              #w=1 means species was available for sampling
              
              a0[i] ~ dnorm(a0.mean, tau.a0)
                             
              a1[i] ~ dnorm(ifelse(i==10,pooled.mean,a1.mean), 
                            ifelse(i==10,(1/pooled.var),tau.a1))

              b0[i] ~ dnorm(b0.mean, tau.b0)"
```

### Write the JAGS script
```{r}
# Function to create text file
write.model <- function(priors){
  mod <- paste("
    model{
    # Define hyperprior distributions: intercepts
    omega ~ dunif(0,1)
    
    mean.a0 ~ dunif(0,1)
    a0.mean <- log(mean.a0)-log(1-mean.a0)
    tau.a0 ~ dgamma(0.1, 0.1)
    
    mean.a1 ~ dunif(0,1)
    a1.mean <- log(mean.a0)-log(1-mean.a0)
    tau.a1 ~ dgamma(0.1, 0.1)
    
    mean.b0 ~ dunif(0,1)
    b0.mean <- log(mean.b0)-log(1-mean.b0)
    tau.b0 ~ dgamma(0.1, 0.1)

    ",priors,"

      #Estimate occupancy of species i at point j
      for (j in 1:J){
        logit(psi[j,i]) <- a0[i] + a1[i]*cov[j]
        Z[j,i] ~ dbern(psi[j,i]*w[i])
    
        #Estimate detection of i at point j during survey k
        for(k in 1:K[j]){
          logit(p[j,k,i]) <-  b0[i]
          obs[j,k,i] ~ dbern(p[j,k,i]*Z[j,i])
    }
    }
    }
    
    #Estimate total richness by adding observed and unobserved species
    n0<-sum(w[(spec+1):(spec+aug)])
    N<-spec+n0
    
    }
    ")
  writeLines(mod, "samplemod.txt") 
}

write.model(priors = priors)
```

### Run model

```{r}
# List of data to send to model
datalist <- list(J = nsite, K = Ks, obs = obs.aug, 
                 spec = 9, aug = 1, cov = cov)

# Parameters to save after model is analyzed
parms <- c('N', 'a0', 'b0', 'a1', 'Z', 'a1.mean', 'pooled.mean',
           'pooled.var')

# Initial values for the Markov chains
init.values<-function(){
  maxobs <- apply(obs.aug, c(1,3), max)
  inits <- list(
    w = rep(1,nspec),
    a0 = rnorm(n = nspec),
    a1 = rnorm(n = nspec),
    b0 = rnorm(n = nspec),
    Z = maxobs)
}

# Send model to JAGS
# model <- jags(model.file = 'samplemod.txt', data = datalist,
#               n.chains = 3, parameters.to.save = parms,
#               inits = init.values, n.burnin = 1000,
#               n.iter = 5000, n.thin = 3)

#Save/load model
# saveRDS(model, file = "sample_mod.rds")
model <- readRDS(file = "sample_mod.rds")
```

### Figures

#### Check to see if aggregation worked

```{r}

```

#### Regional richness estimates

#### Site-level richness estimates

#### Covariate responses